## Einfache Optimierungen


### Ohne Berücksichtigung der Marktvolatilität
```{r message=FALSE, warning=FALSE, echo=FALSE}
suppressPackageStartupMessages({
  library(dplyr)
  library(stringr)
  library(purrr)
  library(pbmcapply)
  library(tidyr)
  library(ggplot2)
  library(data.table)
  library(dtplyr)
  library(arrow)
  library(microbenchmark)
  library(profvis)
  library(dqrng)
  library(keras)
  library(magrittr)
  library(parallel)
  library(cumstats)
})

source("R/02-data.R")
source("R/03-analysis.R")
Rcpp::sourceCpp('src/calc_payoff_per_title.cpp')

data_wide_10 <- arrow::read_feather("data/steps/data_wide_10.feather")

set.seed(123456)
train_idx <- sample(x = nrow(data_wide_10), size = floor(0.8 * nrow(data_wide_10)))
test_idx <- setdiff(seq_len(nrow(data_wide_10)), train_idx)

both_first <- c("buy", "sell")[sample(c(1, 2), nrow(data_wide_10), replace = TRUE)]

```


Eine erste Möglichkeit, optimale Kaufs- und Verkaufspreise zu finden besteht darin, diese im Testdatensatz mittels einfacher Optimierung zu ermitteln. In einer ersten sehr einfachen Evaluation sollen Kaufs- und Verkaufsmarken als prozentuale Abweichungen vom aktuellen Preis festgelegt werden. Als Startgrösse bietet sich hierbei der "Open" Kurs des jeweiligen Tages an. Die resultierenden Payoffs bei einer solchen Festlegung lassen sich dann ins Verhältnis zum Referenzpayoff mit Glattstellung der Deltaposition bei Tagesende stellen. Ein Payoff-Verhältnis über 1 kennzeichnet damit eine Strategie, welche der Referenzstrategie überlegen ist. Verhältnisse unter 1 kennzeichnen unterlegene Strategien. 


``` {r, fig.cap='Payoffvergleich bei symmetrischer Abweichung vom Eröffnungspreis', fig.asp=0.6, fig.pos = '!H', variation-factor-open, echo=FALSE, message=FALSE, warning=FALSE}

variation_factor_open_file_name <- "data/optimizations/variation_factor_open.feather"
data_variation <- select(data_wide_10, Close_1, Open = "Open_0", Low = "Low_0", High = "High_0", Close_0)
opt_payoff_sym <- function(move, data, col, both_first, scale_fct = 1) {
  sum(calc_payoff_const_gamma(data, buy = (1 - move) * data[[col]], sell = (1 + move) * data[[col]], both_first = both_first), na.rm = TRUE) / scale_fct
}

if (file.exists(variation_factor_open_file_name)) {
  bootstraped_variation_factor_open <- arrow::read_feather(variation_factor_open_file_name)
} else {
  scale_fct_train <- sum(calc_payoff_const_gamma(data_variation[train_idx, ], both_first = both_first[train_idx]))
  bootstraped_variation_factor_open <- bootstrap_variation_factor(
    col = "Open",
    move = seq(0, 0.1, 0.001),
    data = data_variation[train_idx, ],
    both_first = both_first[train_idx],
    R = 100,
    mc.cores = ceiling(detectCores() * 0.51)
  )
  
  arrow::write_feather(bootstraped_variation_factor_open, variation_factor_open_file_name)
}

plot_variation_factor(bootstraped_variation_factor_open)

```

Abbildung \@ref(fig:symmetric_open_change) veranschaulicht dieses Verhältnis bei variierender symmetrischer Abweichung vom Startpreis. Lesebeispiel: Werden die Kaufs- und Verkaufpreise zum Handel untertags 2.5% unter resp. über dem Eröffnungskurs des jeweiligen Tages gesetzt, so resultiert ein Gewinn, welcher rund 8% über demjenigen der Referenz bei alleinigem Ausgleich am Abend liegt. 

Bei genauerer Betrachtung weist die Kurve einige interessante Eigenschaften auf: Der höchste Payoff wird bei einer symmetrischen Auslenkung des Preises um `r bootstraped_variation_factor_open$move[which.max(bootstraped_variation_factor_open$original)] * 100`% erreicht. Der Payoffüberschüss beträgt an diesem Punkt rund `r round((bootstraped_variation_factor_open$original[which.max(bootstraped_variation_factor_open$original)] - 1) * 100, 1)`%. Gleichzeitig zeigt sich, dass ein mehr oder weniger konstanter Paypoff-Überschuss von rund 8% im ganzen Auslenkungsbereich von 0.7 bis rund 4% erreicht werden kann. Während im Bereich tieferer Auslenkungen viele kleinere Gewinne realisiert werden, sind es beim setzen breiterer Schranken nur noch wenige, dafür grössere. Die Kurve zeigt, dass sich diese beiden Effekte im genannten Bereich in etwa die Waage halten. Dieses Ergebnis ist für einen Optionshändler insofern interessant, als dass die genaue Preisbestimmmung gar nicht von so grosser Relevanz sein könnte. Wichtig dabei zu erwähnen ist auch, dass während der Datenbereinigung tendenziell eher grosse Auslenkungen aus dem Datensatz entfernt wurden (\@ref(bereinigung)). Werden vermehrt auch extreme Marktbewegungen zugelassen, verschiebt sich die optimale Auslenkung der Preisschranken nach oben. In Kombination mit der Erkenntnis, dass auch bei stärkerer Bereinigung gute Payoffs bis 4% Auslenkung vom Eröffnungspreis erreicht werden, könnte dies auch eine Motivation sein, die Preise eher breiter zu setzen.

Eine weitere Besonderheit der Kurve zeigt sich mit dem Abwärtsknick bei einer Auslenkung bei sehr kleinen Auslenkungen. Erklären lässt sich dieser Knick dadurch, dass bei allen Kursverläufen, bei denen der Eröffnungskurs gleichzeit dem Höchst-, resp. Tiefstkurs des jeweiligen Tages entspricht mindestens eine Marke nicht mehr erreicht werden kann. Bereits beim setzen etwas grösserer Schranken wird dieser Effekt allerdings wieder mehr als ausgeglichen.

Auffällig ist auch die Tatsache, dass bei einer Auslenkung von 0 (und damit einem Wiederherstellen der Delta-Neutralität gleich zum Eröffnungskurs) eine deutlich bessere Performance als die Referenzstrategie aufweist. Dies lässt sich damit erklären, als dass die Werte im Datensatz offenbar eine Tendenz des "Overshootings" der Eröfnungspreise zeigen. Das beobachtete Bild lässt vermuten, dass sich die Preise im Laufe des Tages in der Tendenz wieder eher Richung Schlusskurs des Vortages entwickeln. Ein Ausgleich der aufgebauten Delta-Position "über Nacht" gleich zu Beginn des Handelstages scheint daher ebenfalls besser Ergebnisse zu liefern als die Referenzstartegie.

Schliesslich stellt sich auch die Frage, inwiefern die gefundenen Ergebnisse als statistisch signifikant bezeichnet werden können. Zur Beurteilung dieser Frage wurden mittels Bootsprapverfahren ein 95%-Konfidenzband der Kurve ermittelt. Dieses ist als grau schraffierte Fläche am Rand der Kurve ersichtlich. Es zeigt sich, dass dieses Bank relativ schmal ausfällt. Auch dies kann als direkte Konsequenz der asuführlichen Datenbereinigung gesehen werden. Diese führt dazu, dass auch über verschiedene Boostrap-Samples hinweg die Payoffs stabil und wenig beeinflusst durch einzelne Beobachtungen ausfallen.


```{r}
scale_fct_train <- sum(calc_payoff_const_gamma(data_variation[test_idx, ], both_first = both_first[test_idx]))
payoff_factor_test_max <- opt_payoff_sym(
  move = 0.009, 
  data = data_variation[test_idx, ], 
  col = "Open",
  both_first = both_first[test_idx],
  scale_fct = scale_fct_train
)

payoff_factor_test_4 <- opt_payoff_sym(
  move = 0.04, 
  data = data_variation[test_idx, ], 
  col = "Open",
  both_first = both_first[test_idx],
  scale_fct = scale_fct_train
)

```

Als zweites Mass zur Beurteilung der Aussagekraft der gefundenen Ergebnisse lassen sich zudem auch die Werte des Testdatensatzes heranziehen. In diesem beträgt der Payoffüberschuss im Vergleich zur Referenzstartegie bei 0.9% Auslenkung ebenfalls rund `r round((payoff_factor_test_max - 1) * 100, 1)`% und auch bei einer Auslenkung von 4% kommt der Überschuss bei `r round((payoff_factor_test_4 - 1) * 100, 1)` zu liegen. Beide Werte zeigen hohe Ähnlichkeit mit dem Traingsdatensatz und unterstreichen damit auf Signifikanz der Ergebnisse.


### Mit Berücksichtigung der Marktvolatilität


```{r}

data_variation_vol_paths <- c("data/optimizations/bootstraped_variation_factor_open_low.feather", "data/optimizations/bootstraped_variation_factor_open_high.feather")

if (!all(map_lgl(data_variation_vol_paths, ~file.exists(.)))) {
  
  # split data into low and high varioance groups
  data_wide_10_vol <- arrow::read_feather("data/steps/data_wide_10_vol.feather")
  vol_10 <- data_wide_10_vol$Vol_10
  data_variation_vol <- data_wide_10 %>% select(Ticker, Date, Close_1, Open = "Open_0", Low = "Low_0", High = "High_0", Close_0) %>% mutate(Vol_10 = vol_10)
  
  vol_10_median <- data_variation_vol %>%
    mutate(ID = seq_len(nrow(.))) %>%
    arrange(Ticker, Date) %>%
    group_by(Ticker) %>%
    select(ID, Ticker, Vol_10) %>%
    group_split() %>%
    pbmclapply(function(x) list(ID = x$ID, Vol_10_med = cummedian(x$Vol_10)), mc.cores = 3) %>%
    bind_rows()
  
  data_variation_vol <- data_variation_vol %>% 
    mutate(ID = seq_len(nrow(.))) %>% 
    left_join(vol_10_median, by = "ID") %>% 
    select(-ID)
  
  data_variation_vol <- data_variation_vol %>% mutate(Vol_Group = factor(if_else(Vol_10 <= Vol_10_med, "Low", "High"), levels = c("Low", "High")))
  
  
  # find opimal move
  train_idx_low <- intersect(train_idx, which(data_variation_vol$Vol_Group == "Low"))
  bootstraped_variation_factor_open_low <- bootstrap_variation_factor(
    col = "Open",
    move = seq(0, 0.1, 0.001),
    data = data_variation_vol[train_idx_low, ],
    both_first = both_first[train_idx_low],
    R = 0,
    mc.cores = ceiling(detectCores() * 0.51)
  )
  write_feather(bootstraped_variation_factor_open_low, data_variation_vol_paths[1])
  
  train_idx_high <- intersect(train_idx, which(data_variation_vol$Vol_Group == "High"))
  bootstraped_variation_factor_open_high <- bootstrap_variation_factor(
    col = "Open",
    move = seq(0, 0.1, 0.001),
    data = data_variation_vol[train_idx_high, ],
    both_first = both_first[train_idx_high],
    R = 0,
    mc.cores = ceiling(detectCores() * 0.51)
  )
  write_feather(bootstraped_variation_factor_open_high, data_variation_vol_paths[2])
  
} else {
  bootstraped_variation_factor_open_low <- read_feather(data_variation_vol_paths[1])
  bootstraped_variation_factor_open_high <- read_feather(data_variation_vol_paths[2])
}

plot_variation_factor(bootstraped_variation_factor_open_high)
plot_variation_factor(bootstraped_variation_factor_open_low)

```



