## Klassifikationsverfahren

```{r message=FALSE, warning=FALSE, echo=FALSE}
suppressPackageStartupMessages({
  library(tidyverse)
  library(RANN)
  library(RANN.L1)
  library(digest)
  library(pbmcapply)
  library(parallel)
  library(arrow)
})

source("R/03-analysis.R")

```



Die ökomische Theorie scheint keinen offensichtlichen Grund zu liefern, weshalb die Volatilität des aktuellen Tages in genau 2 (oder x) Gruppen eingeteilt werden sollte. Auf der andern Seite haben bisherige Analsen gezeigt, dass die aktuelle Volatilität ein erklärender Faktor für die aktuelle Volatilität sein kann. Im vorliegenden Kapitel soll dieser Gedanke weiter verfolgt und ausgebaut werden. 

Die Idee besteht darin, nicht lediglich x vordefinierte Gruppen für symmetrische Abweichungen zu finden, viel mehr soll versucht werden, ähnliche Kursverläufe wie den aktuellen in der Vergangenheit zu finden und individuell darauf zu reagieren. Die zugrundliegende Hypothese dieses Vorgehens ist dabei, dass bei ausreichender Historie in der Vergangenheit ähnliche Muster erkannt werden können und daraus Rückschlüsse auf die Zukunft (genauer: die Kursentwicklung des aktuellen Tages) gezogen werden können. 

Da es sehr unwahrscheinlich ist, die genau gleichen Kursverläufe in der Histore wiederzufinden, muss ein Ähnlichkeitsmass, resp. ein Distanzmass definiert werden, um die Nähe der Kursverläufe zu bestimmen. Um diese zu berechnen formulieren wir für jeden Eintrag $i$ den bisherigen Kursverlauf als Vektor $hist$ in der Form. 

$$ hist_{i, t} = (Open_{i, t}, High_{i, t}, Low_{j, t+1}, Close_{i, t+1}, Open_{i, t+1}, ..., Close_{i, 1}, Open_{i, 0}) $$

Der zweite Index gibt dabei an, wieviele Tage der Vergangenheit hierbei mit einbezogen werden. Ein Index von 0 bezieht sich auf den zu prognostizierenden, aktuellen Tag. Um die Ähnlichkeit zweier Einträge $i$ und $j$ zu berechnen, bieten sich 2 Distanzmasse an:

1) Die Manhattan Distanz (auch L1-Norm)  
$$ 
\Vert hist_{i,t} - hist_{j,t}\rVert_1 =  \lvert Open_{i,t} - Open_{j,t} \rvert + \lvert High_{i,t} - High_{j,t} \rvert + \ldots + \lvert Open_{j,0} - Open_{j,0} \rvert
$$


2) Die Euklidische Distanz (auch L2-Norm)
$$ 
\Vert hist_{i,t} - hist_{j,t}\rVert_2  = \sqrt{(Open_{i,t} - Open_{j,t})^2 + (High_{i,t} - High_{j,t})^2 + \ldots + (Open_{j,0} - Open_{j,0})^2}
$$

Beide Masse sollen nachfolgend verwendet und verglichen werden.

### Preisprognose

Mithilfe obiger Distanzmasse lassen sich für jeden Kursverlauf, die k ähnlichsten ander Kursverläufe im Datensatz ermitteln. Dazu seien zuerst aber eingige Übelegungen zur Berechnungskomplexität des Problems gemacht: Der vorliegende bereinigte Datensatz weist `r format(nrow(data_wide_10), big.mark = "'"` tägliche Kursverläufe auf. Soll jeder Kursverlauf mit jedem andern verglichen werden, so ergeben sich bei einem Brute-Force Ansatz `format(nrow(data_wide_10)`^2 Distanzberechungen. Unter Berücksichtigung der Tatsache, dass das Problem symmetrisch ist und jeder Kursverlauf nicht mit sich selbst verglichen werden muss halbiert sich die Komplexität zwar um mehr als die Hälfte, bleibt aber so gross, dass es zum Zeitpunkt des Schreibens dieser Arbeit nicht innerhalb weniger Sekunden oder Minuten auf einem handelsüblichen Heim-Computer berechnet werden kann.

Die für die Nearest Neighbors Suche eingesetzten Bibliotheken greifen daher typischerweise auf sophistiziertere Vorgehensweisen zurück. Eine davon sieht die Verwendung von Multidimensionalen Suchbäumen (Search Trees, auch Kd-Trees). Diese gehen auf eine Idee von \@ref(bentley) zurück. Diese basiert darauf, dass jede Dimension in 2 Teile aufgeteilt wird (z.B. beim Median). Dadruch wird der Raum in viele kleinere Sub-Räume aufgeteilt. Der Algorithmus macht sich dabei zu Nutze, dass er nicht den ganzen Raum absuchen muss, sondern beginnend im eigenen Sub-Raum hin zu den benachtbarten Räumen, bis dass die geforderte Anzahl nächster Nachbarn gefunden ist. Allerdings ist dabei sowohl der Aufbau des Baumes wie auch die Suche im Baum mit Berechnungszeit verbunden. Zeit lässt sich debei einsparen, wenn das Problem auf eine approximative Suche unter der Inkaufname eines Fehlers reduziert wird einsparen.

Die Anzahl der Dimensionen beeinflusst dabei die Berechnungszeit erheblich. Im vorliegenden Fall liegt diese bei der Berücksichtigung einer Historie von 10 Tagen à 4 Werten bei 41, wenn zusätzlich auch der (bekannte) Eröffnungspreis des aktuellen Tages mit einbezogen wird. Tests ergaben, dass die dafür benötigte Rechenzeit nicht praktikabel war. Die zu verwendende Zeitperiode wurde daher auf 3 Tage beschränkt. Dies resultiert in einer deutlichen Reduktion der Suchdimensionen auf 13.

Der vorliegende Fall unterscheidet sich von andern Nearest Neighbor Problemen dadurch, als dass für jeden Eintrag lediglich Kursverläufe der Vergangenheit bertrachtet werden sollten. Im Hinblick auf die Suchstrukur bedeutet dies, dass der KD-Tree nicht nur einmalig aufgebaut und danach für alle Verläufe auf Nachbarn durchsucht werden kann. Viel mehr muss der KD-Tree für jedes Datum mit allen Kursverläufen vor diesem Datum neu aufgebaut werden.[^Natürlich sind auch Mischlösungen denkbar, bei denen nur alle x Daten der Tree neu aufgebaut wird und dafür mehr Nachbarn ermittelt werden, die im Nachgang um nicht vorher realsierte Verläufe gefiltert würden. Dies hat aber das Problem, dass a) mehr Nachbarn ermittelt werden müssen und b) nicht 100% sichergestellt ist, dass die Anzahl "Reservenaachbarn" ausreichen.] Dieser spezielle Setup kommt einer Brute-Force Methode ihrerseits wieder entgegen, da aufgrund des Datums-Filter nicht stehts alle Einträge durchsucht werden müssten.

Beiden Ansätzen gemein ist hingegen, dass sie sich sehr gut parallelisieren lassen und Bibliotheken zur Verfügung stehen, welche diese Methoden effizient implementieren. Wir entscheiden uns um vorliegenden Fall für eine KD-Tree Implementation ohne Approximation. Auf einem Rechner mit 40 Cores (20 physisch, 20 Hyperthreading Cores) dauert die Berechnung von 50 Nachbarn beibe ca. 2  Stunden im Falle des euklidischen Distanzmasses und ca. 3 Stunden im Falle der Manhattan Distanz. Dieser Hohe Anspruch eines KNN-Vorgehens an die Rechenleistung sollte bei der späteren Abwägung verschiedener Algorithmen mit berücksichtigt werden. Erwähnenswert scheint hingegen auch, dass eine allfälligen Anwendung der Methode später nur wenige Titel (resp. nur diejenigen des aktuellen Tages) berechnet werden müssten. Dies ist auch unter der Verwendung einer KNN-Methode in wenigen Sekunden möglich. 

```{r, knn-calculation, echo=FALSE}

data_wide_10 <- arrow::read_feather("data/steps/data_wide_10.feather")
data_knn_3 <- select(data_wide_10, c("Date", levels(interaction(c("Open_", "Low_", "High_", "Close_"), 1:3, sep="")), "Open_0")) %>%
  arrange(Date)

nn_3_eucl_path <- c("data/knn/nn_3_eucl_idx.feather", "data/knn/nn_3_eucl_dists.feather")
if (!all(map_lgl(nn_3_eucl_path, ~file.exists(.)))) {
  
  nn_3_eucl <- find_nn(data = data_knn_3, distance = "euclidean", k = 50, mc.cores = ceiling(detectCores() * 0.51))
  write_feather(as_tibble(nn_3_eucl$nn.idx), nn_3_eucl_path[1])
  write_feather(as_tibble(nn_3_eucl$nn.dists), nn_3_eucl_path[2])
  
  nn_3_eucl_idx <- read_feather(nn_3_eucl_path[1])
  nn_3_eucl_idx_hash <- digest(nn_3_eucl$idx)
  
  nn_3_eucl_dists <- read_feather(nn_3_eucl_path[2])
  nn_3_eucl_dists_hash <- digest(nn_3_eucl_dists)
  
} else {
  nn_3_eucl_idx <- read_feather(nn_3_eucl_path[1])
  nn_3_eucl_dists <- read_feather(nn_3_eucl_path[2])
}

nn_3_manh_path <- c("data/knn/nn_3_manh_idx.feather", "data/knn/nn_3_manh_dists.feather")
if (!all(map_lgl(nn_3_manh_path, ~file.exists(.)))) {
  
  nn_3_manh <- find_nn(data = data_knn_3, distance = "manhattan", k = 50, mc.cores = ceiling(detectCores() * 0.51))
  write_feather(as_tibble(nn_3_manh$nn.idx), nn_3_manh_path[1])
  write_feather(as_tibble(nn_3_manh$nn.dists), nn_3_manh_path[2])
  
  nn_3_manh$idx <- read_feather(nn_3_manh_path[1])
  nn_3_manh_idx_hash <- digest(nn_3_manh$idx)
  
  nn_3_manh$dists <- read_feather(nn_3_manh_path[2])
  nn_3_manh_dists_hash <- digest(nn_3_manh$dists)
  
} else {
  nn_3_manh_idx <- read_feather(nn_3_manh_path[1])
  nn_3_manh_dists <- read_feather(nn_3_manh_path[2])
}

```


Nur 3 vorangehende Arbeitstage
