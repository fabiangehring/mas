{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import feather\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups_per_col = 30\n",
    "ind_categorical_data_train = pd.read_feather(\"../data/ind_categorical_data_train.feather\")\n",
    "ind_categorical_labels_train = pd.read_feather(\"../data/ind_categorical_labels_train.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ind_categorical_data_train.to_numpy()\n",
    "train_label_close = to_categorical(ind_categorical_labels_train.close.to_numpy(), n_groups_per_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ind_categorical_model(train_data, train_labels):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=512, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(n_groups_per_col, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_data, train_labels, validation_split=0.2, batch_size=512, epochs=20, verbose=1)\n",
    "    \n",
    "    return (history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4342137 samples, validate on 1085535 samples\n",
      "Epoch 1/20\n",
      "4342137/4342137 [==============================] - 32s 7us/step - loss: 3.2727 - accuracy: 0.0806 - val_loss: 3.1234 - val_accuracy: 0.1051\n",
      "Epoch 2/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.1757 - accuracy: 0.0899 - val_loss: 3.0821 - val_accuracy: 0.1033\n",
      "Epoch 3/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.1217 - accuracy: 0.0968 - val_loss: 3.2300 - val_accuracy: 0.0718\n",
      "Epoch 4/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1069 - accuracy: 0.0986 - val_loss: 3.1174 - val_accuracy: 0.0997\n",
      "Epoch 5/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1490 - accuracy: 0.0938 - val_loss: 3.2244 - val_accuracy: 0.0769\n",
      "Epoch 6/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.0996 - accuracy: 0.0992 - val_loss: 3.0555 - val_accuracy: 0.1080\n",
      "Epoch 7/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0953 - accuracy: 0.0996 - val_loss: 3.1197 - val_accuracy: 0.0917\n",
      "Epoch 8/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0967 - accuracy: 0.0991 - val_loss: 3.0443 - val_accuracy: 0.1106\n",
      "Epoch 9/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1035 - accuracy: 0.0980 - val_loss: 3.0636 - val_accuracy: 0.1003\n",
      "Epoch 10/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1232 - accuracy: 0.0955 - val_loss: 3.0392 - val_accuracy: 0.1081\n",
      "Epoch 11/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1115 - accuracy: 0.0972 - val_loss: 3.0850 - val_accuracy: 0.1057\n",
      "Epoch 12/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1224 - accuracy: 0.0979 - val_loss: 3.0461 - val_accuracy: 0.1104\n",
      "Epoch 13/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0842 - accuracy: 0.1012 - val_loss: 3.0416 - val_accuracy: 0.1066\n",
      "Epoch 14/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1017 - accuracy: 0.0985 - val_loss: 3.0926 - val_accuracy: 0.1106\n",
      "Epoch 15/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1164 - accuracy: 0.0988 - val_loss: 3.0384 - val_accuracy: 0.1094\n",
      "Epoch 16/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0697 - accuracy: 0.1036 - val_loss: 3.0273 - val_accuracy: 0.1111\n",
      "Epoch 17/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0982 - accuracy: 0.0994 - val_loss: 3.0690 - val_accuracy: 0.1004\n",
      "Epoch 18/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1152 - accuracy: 0.0987 - val_loss: 3.0307 - val_accuracy: 0.1072\n",
      "Epoch 19/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0997 - accuracy: 0.0983 - val_loss: 3.0301 - val_accuracy: 0.1075\n",
      "Epoch 20/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1110 - accuracy: 0.0986 - val_loss: 3.0497 - val_accuracy: 0.0997\n",
      "Train on 4342137 samples, validate on 1085535 samples\n",
      "Epoch 1/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.2935 - accuracy: 0.0793 - val_loss: 3.0865 - val_accuracy: 0.1090\n",
      "Epoch 2/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1899 - accuracy: 0.0868 - val_loss: 3.1409 - val_accuracy: 0.0972\n",
      "Epoch 3/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1386 - accuracy: 0.0942 - val_loss: 3.0659 - val_accuracy: 0.1041\n",
      "Epoch 4/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1584 - accuracy: 0.0905 - val_loss: 3.2481 - val_accuracy: 0.0726\n",
      "Epoch 5/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1232 - accuracy: 0.0954 - val_loss: 3.1044 - val_accuracy: 0.0943\n",
      "Epoch 6/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0944 - accuracy: 0.0996 - val_loss: 3.0735 - val_accuracy: 0.1079\n",
      "Epoch 7/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.0876 - accuracy: 0.1002 - val_loss: 3.0438 - val_accuracy: 0.1078\n",
      "Epoch 8/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1015 - accuracy: 0.0984 - val_loss: 3.1714 - val_accuracy: 0.0976\n",
      "Epoch 9/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1091 - accuracy: 0.0971 - val_loss: 3.1195 - val_accuracy: 0.0954\n",
      "Epoch 10/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1293 - accuracy: 0.0937 - val_loss: 3.0308 - val_accuracy: 0.1062\n",
      "Epoch 11/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1310 - accuracy: 0.0936 - val_loss: 3.0860 - val_accuracy: 0.0962\n",
      "Epoch 12/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1057 - accuracy: 0.0974 - val_loss: 3.0750 - val_accuracy: 0.1105\n",
      "Epoch 13/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1106 - accuracy: 0.0972 - val_loss: 3.0520 - val_accuracy: 0.1018\n",
      "Epoch 14/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1240 - accuracy: 0.0945 - val_loss: 3.0517 - val_accuracy: 0.1108\n",
      "Epoch 15/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1419 - accuracy: 0.0938 - val_loss: 3.2875 - val_accuracy: 0.0682\n",
      "Epoch 16/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0889 - accuracy: 0.1007 - val_loss: 3.0385 - val_accuracy: 0.1011\n",
      "Epoch 17/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.0874 - accuracy: 0.0998 - val_loss: 3.0417 - val_accuracy: 0.1013\n",
      "Epoch 18/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.0935 - accuracy: 0.0992 - val_loss: 3.0609 - val_accuracy: 0.1113\n",
      "Epoch 19/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1166 - accuracy: 0.0967 - val_loss: 3.0304 - val_accuracy: 0.1100\n",
      "Epoch 20/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.0965 - accuracy: 0.0982 - val_loss: 3.0211 - val_accuracy: 0.1065\n",
      "Train on 4342137 samples, validate on 1085535 samples\n",
      "Epoch 1/20\n",
      "4342137/4342137 [==============================] - 32s 7us/step - loss: 3.3948 - accuracy: 0.0640 - val_loss: 3.2418 - val_accuracy: 0.0789\n",
      "Epoch 2/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.2540 - accuracy: 0.0761 - val_loss: 3.2318 - val_accuracy: 0.0810\n",
      "Epoch 3/20\n",
      "4342137/4342137 [==============================] - 32s 7us/step - loss: 3.2467 - accuracy: 0.0775 - val_loss: 3.2440 - val_accuracy: 0.0812\n",
      "Epoch 4/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.2426 - accuracy: 0.0784 - val_loss: 3.2310 - val_accuracy: 0.0794\n",
      "Epoch 5/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.2648 - accuracy: 0.0741 - val_loss: 3.3352 - val_accuracy: 0.0609\n",
      "Epoch 6/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2803 - accuracy: 0.0719 - val_loss: 3.2544 - val_accuracy: 0.0764\n",
      "Epoch 7/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2509 - accuracy: 0.0770 - val_loss: 3.2329 - val_accuracy: 0.0804\n",
      "Epoch 8/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2401 - accuracy: 0.0786 - val_loss: 3.2240 - val_accuracy: 0.0813\n",
      "Epoch 9/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2351 - accuracy: 0.0794 - val_loss: 3.2359 - val_accuracy: 0.0781\n",
      "Epoch 10/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2324 - accuracy: 0.0800 - val_loss: 3.2276 - val_accuracy: 0.0810\n",
      "Epoch 11/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2316 - accuracy: 0.0802 - val_loss: 3.2728 - val_accuracy: 0.0714\n",
      "Epoch 12/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2299 - accuracy: 0.0804 - val_loss: 3.2193 - val_accuracy: 0.0828\n",
      "Epoch 13/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2286 - accuracy: 0.0806 - val_loss: 3.2411 - val_accuracy: 0.0783\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2279 - accuracy: 0.0807 - val_loss: 3.2296 - val_accuracy: 0.0795\n",
      "Epoch 15/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.2276 - accuracy: 0.0808 - val_loss: 3.2226 - val_accuracy: 0.0822\n",
      "Epoch 16/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2265 - accuracy: 0.0808 - val_loss: 3.2288 - val_accuracy: 0.0796\n",
      "Epoch 17/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2262 - accuracy: 0.0811 - val_loss: 3.2307 - val_accuracy: 0.0818\n",
      "Epoch 18/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2262 - accuracy: 0.0811 - val_loss: 3.2194 - val_accuracy: 0.0819\n",
      "Epoch 19/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2253 - accuracy: 0.0814 - val_loss: 3.2204 - val_accuracy: 0.0822\n",
      "Epoch 20/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.2254 - accuracy: 0.0812 - val_loss: 3.2149 - val_accuracy: 0.0837\n"
     ]
    }
   ],
   "source": [
    "# low\n",
    "train_label_low = to_categorical(ind_categorical_labels_train.low.to_numpy(), n_groups_per_col)\n",
    "(indipendent_categorical_low_history, indipendent_categorical_low_model) = fit_ind_categorical_model(train_data, train_label_low)\n",
    "feather.write_dataframe(pd.DataFrame.from_dict(indipendent_categorical_low_history.history), \"../data/indipendent_categorical_low_history.feather\")\n",
    "indipendent_categorical_low_model.save(\"../data/indipendent_categorical_low_model.hdf5\")\n",
    "\n",
    "# high\n",
    "train_label_high = to_categorical(ind_categorical_labels_train.high.to_numpy(), n_groups_per_col)\n",
    "(indipendent_categorical_high_history, indipendent_categorical_high_model) = fit_ind_categorical_model(train_data, train_label_high)\n",
    "feather.write_dataframe(pd.DataFrame.from_dict(indipendent_categorical_high_history.history), \"../data/indipendent_categorical_high_history.feather\")\n",
    "indipendent_categorical_high_model.save(\"../data/indipendent_categorical_high_model.hdf5\")\n",
    "\n",
    "# close\n",
    "train_label_close = to_categorical(ind_categorical_labels_train.close.to_numpy(), n_groups_per_col)\n",
    "(indipendent_categorical_close_history, indipendent_categorical_close_model) = fit_ind_categorical_model(train_data, train_label_close)\n",
    "feather.write_dataframe(pd.DataFrame.from_dict(indipendent_categorical_close_history.history), \"../data/indipendent_categorical_close_history.feather\")\n",
    "indipendent_categorical_close_model.save(\"../data/indipendent_categorical_close_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
