{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import feather\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups_per_col = 30\n",
    "ind_categorical_data_train = pd.read_feather(\"../data/ind_categorical_data_train.feather\")\n",
    "ind_categorical_labels_train = pd.read_feather(\"../data/ind_categorical_labels_train.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ind_categorical_data_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ind_categorical_model(train_data, train_labels):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=512, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(n_groups_per_col, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_data, train_labels, validation_split=0.2, batch_size=512, epochs=20, verbose=1)\n",
    "    \n",
    "    return (history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4342137 samples, validate on 1085535 samples\n",
      "Epoch 1/20\n",
      "4342137/4342137 [==============================] - 32s 7us/step - loss: 3.2827 - accuracy: 0.0796 - val_loss: 3.1682 - val_accuracy: 0.0815\n",
      "Epoch 2/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1730 - accuracy: 0.0907 - val_loss: 3.1596 - val_accuracy: 0.0855\n",
      "Epoch 3/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.1268 - accuracy: 0.0963 - val_loss: 3.0724 - val_accuracy: 0.1087\n",
      "Epoch 4/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.1992 - accuracy: 0.0821 - val_loss: 3.4008 - val_accuracy: 0.0390\n",
      "Epoch 5/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4013 - accuracy: 0.0384 - val_loss: 3.4022 - val_accuracy: 0.0390\n",
      "Epoch 6/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4008 - accuracy: 0.0386 - val_loss: 3.4010 - val_accuracy: 0.0390\n",
      "Epoch 7/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4006 - accuracy: 0.0387 - val_loss: 3.4006 - val_accuracy: 0.0390\n",
      "Epoch 8/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4005 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 9/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4005 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 10/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4005 - accuracy: 0.0387 - val_loss: 3.4004 - val_accuracy: 0.0390\n",
      "Epoch 11/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 12/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 13/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 14/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 15/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 16/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 17/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 18/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 19/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4003 - val_accuracy: 0.0390\n",
      "Epoch 20/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.4004 - accuracy: 0.0387 - val_loss: 3.4004 - val_accuracy: 0.0390\n",
      "Train on 4342137 samples, validate on 1085535 samples\n",
      "Epoch 1/20\n",
      "4342137/4342137 [==============================] - 33s 8us/step - loss: 3.2812 - accuracy: 0.0803 - val_loss: 3.0949 - val_accuracy: 0.1130\n",
      "Epoch 2/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.1367 - accuracy: 0.0948 - val_loss: 3.1933 - val_accuracy: 0.0873\n",
      "Epoch 3/20\n",
      "4342137/4342137 [==============================] - 32s 7us/step - loss: 3.1720 - accuracy: 0.0889 - val_loss: 3.1306 - val_accuracy: 0.0968\n",
      "Epoch 4/20\n",
      "4342137/4342137 [==============================] - 35s 8us/step - loss: 3.1139 - accuracy: 0.0976 - val_loss: 3.0751 - val_accuracy: 0.1083\n",
      "Epoch 5/20\n",
      "4342137/4342137 [==============================] - 34s 8us/step - loss: 3.0935 - accuracy: 0.0999 - val_loss: 3.1750 - val_accuracy: 0.0710\n",
      "Epoch 6/20\n",
      "4342137/4342137 [==============================] - 36s 8us/step - loss: 3.1445 - accuracy: 0.0928 - val_loss: 3.1325 - val_accuracy: 0.0947\n",
      "Epoch 7/20\n",
      "3702272/4342137 [========================>.....] - ETA: 4s - loss: 3.1431 - accuracy: 0.0940"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2ddfb83a5b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# high\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_label_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_categorical_labels_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_groups_per_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mindipendent_categorical_high_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindipendent_categorical_high_model\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_ind_categorical_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label_high\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindipendent_categorical_high_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../data/indipendent_categorical_high_history.feather\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mindipendent_categorical_high_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/indipendent_categorical_high_model.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-014a240bb5eb>\u001b[0m in \u001b[0;36mfit_ind_categorical_model\u001b[0;34m(train_data, train_labels)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mas/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/mas/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    184\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# low\n",
    "train_label_low = to_categorical(ind_categorical_labels_train.low.to_numpy(), n_groups_per_col)\n",
    "(indipendent_categorical_low_history, indipendent_categorical_low_model) = fit_ind_categorical_model(train_data, train_label_low)\n",
    "feather.write_dataframe(pd.DataFrame.from_dict(indipendent_categorical_low_history.history), \"../data/indipendent_categorical_low_history.feather\")\n",
    "indipendent_categorical_low_model.save(\"../data/indipendent_categorical_low_model.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high\n",
    "train_label_high = to_categorical(ind_categorical_labels_train.high.to_numpy(), n_groups_per_col)\n",
    "(indipendent_categorical_high_history, indipendent_categorical_high_model) = fit_ind_categorical_model(train_data, train_label_high)\n",
    "feather.write_dataframe(pd.DataFrame.from_dict(indipendent_categorical_high_history.history), \"../data/indipendent_categorical_high_history.feather\")\n",
    "indipendent_categorical_high_model.save(\"../data/indipendent_categorical_high_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close\n",
    "train_label_close = to_categorical(ind_categorical_labels_train.close.to_numpy(), n_groups_per_col)\n",
    "(indipendent_categorical_close_history, indipendent_categorical_close_model) = fit_ind_categorical_model(train_data, train_label_close)\n",
    "feather.write_dataframe(pd.DataFrame.from_dict(indipendent_categorical_close_history.history), \"../data/indipendent_categorical_close_history.feather\")\n",
    "indipendent_categorical_close_model.save(\"../data/indipendent_categorical_close_model.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
